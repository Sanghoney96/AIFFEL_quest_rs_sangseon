{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de7ef56c",
   "metadata": {},
   "source": [
    "# GPT-1 모델\n",
    "https://actionpower.medium.com/%EC%95%A1%EC%85%98%ED%8C%8C%EC%9B%8Clab-gpt-1-generative-pre-training-%EC%95%8C%EC%95%84%EB%B3%B4%EA%B8%B0-f63f18efa625\n",
    "\n",
    "## 1. Encoder block 제거 \n",
    "   decoder만을 사용해 이전 토큰들을 기반으로 순차적으로 다음 토큰을 예측합니다. 즉, 모델이 문맥을 생성하는 데에만 집중합니다\n",
    "   gpt-1은 deocder 부분만 필요로 함으로 기존 transformer 그림에서 encoder 부분을 제거\n",
    "\n",
    "## 2. positional encoding layer\n",
    "   기존 transformer에서는 positional embedding을 cos,sin을 사용하여 구했지만 gpt-1에서는 cos,sin으로 구하지 않고 위치 인코딩을 네트워크가 학습할 수 있도록 임베딩 레이어의 일부로 포함시킴\n",
    "\n",
    "## 3. deocdr masked multi-head Self-attention\n",
    "   \n",
    "   이 부분은 encoder의 참조 없이 decoder 스스로 attention 하는 부분임으로 남겨 놓음\n",
    "   이미 생성된 문장들만 참고하기 위해 masking 사용\n",
    "  \n",
    "## 4. cross attention 제거 \n",
    "   gpt-1 model은 encoder 부분이 필요 없어짐으로 decoder가 encoder로 부터 받는 key,value값을 전달하는 cross attention 제거\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05975191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout\n",
    "from tensorflow.keras import activations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922b340a",
   "metadata": {},
   "source": [
    "## 데이터 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2757fafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_file_path = './data.csv'\n",
    "transformer_data = pd.read_csv('./data/data.csv', encoding ='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "032d3903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49bf537d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11823 entries, 0 to 11822\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Q       11823 non-null  object\n",
      " 1   A       11823 non-null  object\n",
      " 2   label   11823 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 277.2+ KB\n"
     ]
    }
   ],
   "source": [
    "transformer_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68bdd68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_data['length'] = transformer_data['Q'].apply(lambda x: len(x.split()))  # Q열의 문장 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdf2cbde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(transformer_data['length'], bins=50, alpha=0.7, color='blue')\n",
    "plt.title('Distribution of Sentence Lengths')\n",
    "plt.xlabel('Length of Sentences')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd314a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_data['length'] = transformer_data['A'].apply(lambda x: len(x.split()))  # A열의 문장 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60f3bb1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(transformer_data['length'], bins=50, alpha=0.7, color='blue')\n",
    "plt.title('Distribution of Sentence Lengths')\n",
    "plt.xlabel('Length of Sentences')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ba79025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 11823\n"
     ]
    }
   ],
   "source": [
    "num_samples = transformer_data.shape[0]  # 또는 len(transformer_data)\n",
    "print(f'Number of samples: {num_samples}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4737684a",
   "metadata": {},
   "source": [
    "## 데이터 전처리 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1130261",
   "metadata": {},
   "source": [
    "##  SubwordTextEncoder 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd812e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SAMPLES = 11823"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bd75cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "    \n",
    "    # 구두점과의 거리를 만듭니다 (예: \"I am a student.\" -> \"I am a student .\")\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    \n",
    "    # 공백이 두 개 이상일 때 하나로 치환\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    \n",
    "    # 한글과 영어, 구두점(. , ? !)을 제외한 모든 문자를 공백으로 대체\n",
    "    sentence = re.sub(r'[^a-zA-Z0-9.,?!가-힣]', ' ', sentence)\n",
    "    \n",
    "    sentence = sentence.strip()\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "740c8b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = transformer_data['Q'].apply(preprocess_sentence).tolist()\n",
    "answers = transformer_data['A'].apply(preprocess_sentence).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd6161bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후의 22번째 질문 샘플: 가스비 장난 아님\n",
      "전처리 후의 22번째 답변 샘플: 다음 달에는 더 절약해봐요 .\n"
     ]
    }
   ],
   "source": [
    "print('전처리 후의 22번째 질문 샘플: {}'.format(questions[21]))\n",
    "print('전처리 후의 22번째 답변 샘플: {}'.format(answers[21]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f92575d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f17fcb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75be78af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [5758, 610, 2487, 4159]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [2355, 7504, 7, 6268, 97, 1]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a85dd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = tokenizer.vocab_size + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39a15cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [5758, 610, 2487, 4159]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [2355, 7504, 7, 6268, 97, 1]\n"
     ]
    }
   ],
   "source": [
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f990f445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이, 분포를 찍어 봤을때 가장 높게 나오는 수치인 10으로 설정,\n",
    "## 가장 긴 데이터의 경우에 40인 경우도 있지만 40으로 잡을 경우 padding값이 많아짐으로 정확도가 낮아지는 묹제점이 발생 \n",
    "## q,a를 합침으로 10 + 10 + $, 공백 까지 고려해서 22로 설정\n",
    "MAX_LENGTH = 22\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ff957a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef tokenize_and_filter(inputs, outputs):\\n  tokenized_inputs, tokenized_outputs = [], []\\n  \\n  for (sentence1, sentence2) in zip(inputs, outputs):\\n    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\\n    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\\n    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\\n\\n    # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\\n    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\\n      tokenized_inputs.append(sentence1)\\n      tokenized_outputs.append(sentence2)\\n  \\n  # 최대 길이 40으로 모든 데이터셋을 패딩\\n  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\\n      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\\n  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\\n      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\\n  \\n  return tokenized_inputs, tokenized_outputs\\n\\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transformer 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "\"\"\"\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f70e78f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nquestions, answers = tokenize_and_filter(questions, answers)\\nprint('단어장의 크기 :',(VOCAB_SIZE))\\nprint('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\\nprint('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))\\n\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## transforemr question, ansers tokenize \n",
    "\"\"\"\n",
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "891ea7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# gpt 토크나이징 및 필터링\n",
    "def tokenize_and_filter(dialogues):\n",
    "    tokenized_inputs = []\n",
    "  \n",
    "    for dialogue in dialogues:\n",
    "        question = dialogue['question']\n",
    "        answer = dialogue['answer']\n",
    "        \n",
    "        # GPT는 질문과 답변을 하나의 시퀀스로 처리. 구분자로 '$'를 사용\n",
    "        dialogue_sequence = question + \" $\" + answer\n",
    "        \n",
    "        # 정수 인코딩 과정\n",
    "        tokenized_input = START_TOKEN + tokenizer.encode(dialogue_sequence) + END_TOKEN\n",
    "        \n",
    "        # 최대 길이 이하인 시퀀스만 허용\n",
    "        if len(tokenized_input) <= MAX_LENGTH:\n",
    "            tokenized_inputs.append(tokenized_input)\n",
    "    \n",
    "    # 패딩 처리 (최대 길이 기준)\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_inputs, maxlen=MAX_LENGTH, padding='post'\n",
    "    )\n",
    "  \n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d599d948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기: 8166\n",
      "필터링 후의 데이터 샘플 개수: 11324\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 질문과 답변을 하나의 시퀀스로 결합하여 처리\n",
    "dialogues = [{'question': q, 'answer': a} for q, a in zip(questions, answers)]\n",
    "tokenized_inputs = tokenize_and_filter(dialogues)\n",
    "\n",
    "print(f'단어장의 크기: {VOCAB_SIZE}')\n",
    "print(f'필터링 후의 데이터 샘플 개수: {len(tokenized_inputs)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131d5c09",
   "metadata": {},
   "source": [
    "## positionalEncoding, Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb6e2850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass PositionalEncoding(tf.keras.layers.Layer):\\n \\n  def __init__(self, position, d_model):\\n    super(PositionalEncoding, self).__init__()\\n    self.pos_encoding = self.positional_encoding(position, d_model)\\n\\n     \\n  def get_angles(self, position, i, d_model):\\n    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\\n    return position * angles\\n\\n\\n\\n  def positional_encoding(self, position, d_model):\\n    # 각도 배열 생성\\n    angle_rads = self.get_angles(\\n        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\\n        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\\n        d_model=d_model)\\n\\n    # 배열의 짝수 인덱스에는 sin 함수 적용\\n    sines = tf.math.sin(angle_rads[:, 0::2])\\n    # 배열의 홀수 인덱스에는 cosine 함수 적용\\n    cosines = tf.math.cos(angle_rads[:, 1::2])\\n\\n    # sin과 cosine이 교차되도록 재배열\\n    pos_encoding = tf.stack([sines, cosines], axis=0)\\n    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \\n    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\\n\\n    pos_encoding = pos_encoding[tf.newaxis, ...]\\n    return tf.cast(pos_encoding, tf.float32)\\n\\n  def call(self, inputs):\\n    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 포지셔널 인코딩 레이어 , transformerdptjsms Positional Encoding을 sin cos으로 구하였지만 ,gpt-1에서는 layer를 통해 position을 구함\n",
    "\"\"\"\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    " \n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "     \n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    # 각도 배열 생성\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "\n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    # sin과 cosine이 교차되도록 재배열\n",
    "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aad0061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "\n",
    "\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 패딩에 마스크 추가\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2461cc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "## gpt에서는 sin,cos로 위치를 구하지 않고 layer We를 통해 구함\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, max_position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_embedding = self.add_weight(\"pos_embedding\", shape=(max_position, d_model))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size, seq_length, _ = tf.shape(inputs)\n",
    "        return inputs + self.pos_embedding[:seq_length, :]  # 시퀀스 길이에 맞는 위치 임베딩을 추가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0fad53e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNetwork(Layer):\n",
    "    def __init__(self, d_model, d_ff, rate):\n",
    "        super(FeedForwardNetwork, self).__init__()\n",
    "        self.dense1 = Dense(d_ff, activation='relu')\n",
    "        self.dense2 = Dense(d_model)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "        self.layer_norm = LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dropout1(x, training=training)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dropout2(x, training=training)\n",
    "\n",
    "        return self.layer_norm(inputs + x)  # Residual connection and layer norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5039d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TransformerBlock 수정\n",
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = FeedForwardNetwork(d_model, dff, rate)\n",
    "        self.layer_norm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layer_norm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training, mask=None):\n",
    "        # Ensure inputs are processed as needed\n",
    "        attn_output = self.attention({\n",
    "            'query': inputs,\n",
    "            'key': inputs,\n",
    "            'value': inputs,\n",
    "            'mask': mask\n",
    "        })  # Pass the same inputs for Q, K, V\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layer_norm1(inputs + attn_output)\n",
    "\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layer_norm2(out1 + ffn_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "776e72a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiHeadAttention 클래스 수정\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query = self.query_dense(inputs['query'])\n",
    "        key = self.key_dense(inputs['key'])\n",
    "        value = self.value_dense(inputs['value'])\n",
    "        mask = inputs.get('mask')\n",
    "\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # 스케일드 닷 프로덕트 어텐션 함수\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))\n",
    "\n",
    "        # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d85c0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dbad1435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583e7e21",
   "metadata": {},
   "source": [
    "## 모델 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32362581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\ndef encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\\n  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\\n\\n  # 패딩 마스크 사용\\n  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\\n\\n  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\\n  attention = MultiHeadAttention(\\n      d_model, num_heads, name=\"attention\")({\\n          \\'query\\': inputs,\\n          \\'key\\': inputs,\\n          \\'value\\': inputs,\\n          \\'mask\\': padding_mask\\n      })\\n\\n  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\\n  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\\n  attention = tf.keras.layers.LayerNormalization(\\n      epsilon=1e-6)(inputs + attention)\\n\\n  # 두 번째 서브 레이어 : 2개의 완전연결층\\n  outputs = tf.keras.layers.Dense(units=units, activation=\\'relu\\')(attention)\\n  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\\n\\n  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\\n  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\\n  outputs = tf.keras.layers.LayerNormalization(\\n      epsilon=1e-6)(attention + outputs)\\n\\n  return tf.keras.Model(\\n      inputs=[inputs, padding_mask], outputs=outputs, name=name)\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "## gpt -> encoder x\n",
    "\"\"\"\n",
    "\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b2c5c88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef encoder(vocab_size,\\n            num_layers,\\n            units,\\n            d_model,\\n            num_heads,\\n            dropout,\\n            name=\"encoder\"):\\n  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\\n\\n  # 패딩 마스크 사용\\n  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\\n\\n  # 임베딩 레이어\\n  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\\n  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\\n\\n  # 포지셔널 인코딩\\n  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\\n\\n  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\\n\\n  # num_layers만큼 쌓아올린 인코더의 층.\\n  for i in range(num_layers):\\n    outputs = encoder_layer(\\n        units=units,\\n        d_model=d_model,\\n        num_heads=num_heads,\\n        dropout=dropout,\\n        name=\"encoder_layer_{}\".format(i),\\n    )([outputs, padding_mask])\\n\\n  return tf.keras.Model(\\n      inputs=[inputs, padding_mask], outputs=outputs, name=name)\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## gpt model에서는 encoder 부분은 필요 없음 \n",
    "\"\"\"\n",
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layers만큼 쌓아올린 인코더의 층.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "744b4ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "            'query': inputs,\n",
    "            'key': inputs,\n",
    "            'value': inputs,\n",
    "            'mask': look_ahead_mask\n",
    "         })\n",
    "\n",
    "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    \n",
    "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "  ## encoder가 없어짐으로 두 번째 sub layer도 필요 없어짐\n",
    "    \n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fa9e63d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "  # 패딩 마스크\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "  # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b136be",
   "metadata": {},
   "source": [
    "## 교사 강요(Teacher Forcing) 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dbc5b6b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2228/2776559251.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \"\"\"\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Tokenizer 설정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSubwordTextEncoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_from_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_vocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# 데이터 인코딩\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'combined_data' is not defined"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "\"\"\"\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\"\"\"\n",
    "# Tokenizer 설정\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(combined_data, target_vocab_size=2**15)\n",
    "\n",
    "# 데이터 인코딩\n",
    "inputs = [tokenizer.encode(f\"{q}${a}\") for q, a in zip(dialogues, answers)]\n",
    "outputs = [tokenizer.encode(a) for a in answers]  # 모든 답변을 포함\n",
    "\n",
    "# 최대 시퀀스 길이 정의\n",
    "max_length = 22\n",
    "\n",
    "# 패딩 추가\n",
    "inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, maxlen=max_length, padding='post')\n",
    "outputs = tf.keras.preprocessing.sequence.pad_sequences(outputs, maxlen=max_length, padding='post')  # 마지막 요소 제거 필요 없음\n",
    "\n",
    "# 데이터셋 생성\n",
    "dataset = tf.data.Dataset.from_tensor_slices((inputs, outputs))\n",
    "\n",
    "# 데이터셋 캐시, 셔플, 배치 및 프리패치 설정\n",
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c3f0d3",
   "metadata": {},
   "source": [
    "##  모델 정의 및 평가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a152c531",
   "metadata": {},
   "source": [
    "## GPT Model 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e272d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, d_model, num_layers, num_heads, dff, max_position_encoding, rate=0.1):\n",
    "        super(GPTModel, self).__init__()\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, d_model)\n",
    "        self.transformer_blocks = [TransformerBlock(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "        self.final_layer = tf.keras.layers.Dense(vocab_size)  # 최종 출력 형태 (None, 22, vocab_size)\n",
    "\n",
    "    def call(self, inputs, training, mask=None):\n",
    "        # 임베딩을 적용\n",
    "        x = self.embedding(inputs)  # (batch_size, seq_length, d_model)\n",
    "        \n",
    "        for transformer in self.transformer_blocks:\n",
    "            x = transformer(x, training, mask)  # 각 TransformerBlock의 출력\n",
    "          \n",
    "        return self.final_layer(x)  # 최종 레이어에서 vocab_size 차원으로 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b413682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "vocab_size = tokenizer.vocab_size + 2\n",
    "d_model = 128\n",
    "num_layers = 4\n",
    "num_heads = 8\n",
    "dff = 512\n",
    "max_position_encoding = 10\n",
    "rate = 0.1\n",
    "\n",
    "# Create the model\n",
    "model = GPTModel(vocab_size, d_model, num_layers, num_heads, dff, max_position_encoding, rate)\n",
    "\n",
    "# Define input shape for the model\n",
    "input_shape = (None, 22)\n",
    "\n",
    "# Build the model\n",
    "model.build(input_shape)\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "\n",
    "##??? output shape -> multiple ?? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7308d575",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01  # 학습률 설정\n",
    "sgd_optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "model.compile(optimizer= sgd_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5cc161",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbb0a88",
   "metadata": {},
   "source": [
    "## Chatbot Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56666ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "    sentence = tf.expand_dims(\n",
    "        START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "    output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "    for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "        predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "        predictions = predictions[:, -1:, :]\n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "      if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "        break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "      output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1920aac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "    # 입력 문장을 정수 인코딩\n",
    "    encoded_sentence = tokenizer.encode(sentence)  # tokenizer를 사용하여 정수 시퀀스로 변환\n",
    "    input_tensor = tf.convert_to_tensor([encoded_sentence])  # 텐서로 변환하고 배치 차원 추가\n",
    "    \n",
    "    # output_sequence를 텐서로 초기화, 시작 토큰을 포함합니다.\n",
    "    output_sequence = tf.convert_to_tensor([[START_TOKEN]], dtype=tf.int32)  # 시작 토큰으로 초기화\n",
    "\n",
    "    for i in range(MAX_LENGTH):\n",
    "        # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "        predictions = model(inputs=[input_tensor, output_sequence], training=False)\n",
    "        predictions = predictions[:, -1:, :]  # 마지막 시간 단계의 예측값 가져오기\n",
    "        \n",
    "        # 예측된 단어의 정수 인덱스를 가져오기\n",
    "        predicted_id = tf.argmax(predictions, axis=-1)  # 예측된 인덱스\n",
    "        output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)  # output_sequence에 추가\n",
    "        \n",
    "        # 종료 토큰 확인\n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "            break\n",
    "\n",
    "    # 정수 시퀀스를 다시 텍스트 시퀀스로 변환\n",
    "    generated_sentence = tokenizer.decode(output_sequence.numpy()[0])  # 텐서를 넘파이 배열로 변환 후 디코드\n",
    "    return generated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c9c310",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_generation('안녕')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb0e779",
   "metadata": {},
   "source": [
    "## Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f99b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # 인코더에서 패딩을 위한 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "  # 디코더에서 패딩을 위한 마스크\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # 디코더\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3738ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "## 하이퍼파라미터\n",
    "NUM_LAYERS = 6 # 인코더와 디코더의 층의 개수 , layer 수가 늘어나도 residual에서 역전파가 뛰어넘음 -> 늘린다고 과적합은 발생안함 \n",
    "D_MODEL = 512 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수\n",
    "UNITS = 2048 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb3353b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76b864e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297637c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abe19fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32270013",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d9d75e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1f7e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1411e678",
   "metadata": {},
   "source": [
    "## 챗봇 테스트하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfe639e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "    predictions = predictions[:, -1:, :]\n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbe3026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('입력 : {}'.format(sentence))\n",
    "  print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d273a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop out 0.5, max_length = 10\n",
    "sentence_generation('안녕')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f9c319",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_generation('오늘 날씨 어때')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f17ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_generation('오늘 뭐 먹어?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2693c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dropout 0.1, max_length = 10\n",
    "sentence_generation('안녕')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd7eedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_generation('오늘 날씨 어때')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b65973c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_generation('오늘 뭐해?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2faebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_generation('머리 아파')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d5e7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_generation('물건이 망가졌어')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd84640",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
