{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32f594f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 벡터화 함수\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# 머신러닝 모델들\n",
    "from sklearn.naive_bayes import MultinomialNB #다항분포 나이브 베이즈 모델\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# 모델 검증\n",
    "from sklearn.metrics import accuracy_score #정확도 계산\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ca1f02",
   "metadata": {},
   "source": [
    "## 2. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24579c3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플의 수: 8982\n",
      "테스트 샘플의 수: 2246\n"
     ]
    }
   ],
   "source": [
    "num_words = 20000\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=num_words, test_split=0.2)\n",
    "print('훈련 샘플의 수: {}'.format(len(x_train)))\n",
    "print('테스트 샘플의 수: {}'.format(len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3c2e2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 복원\n",
    "word_index = reuters.get_word_index()\n",
    "reverse_word_index = {v: k for k, v in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd903659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_review(text):\n",
    "    return \" \".join([reverse_word_index.get(i - 3, \"?\") for i in text])  # '-3'은 예약된 인덱스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0823a600",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_texts = [decode_review(x) for x in x_train]\n",
    "x_test_texts = [decode_review(x) for x in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb520f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF 변환\n",
    "vectorizer = TfidfVectorizer(max_features=20000)\n",
    "X_train_tfidf = vectorizer.fit_transform(x_train_texts)\n",
    "X_test_tfidf = vectorizer.transform(x_test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbe9468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSA 적용\n",
    "svd = TruncatedSVD(n_components=100)  # 100차원으로 축소\n",
    "normalizer = Normalizer(copy=False)\n",
    "lsa = make_pipeline(svd, normalizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af86a38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lsa = lsa.fit_transform(X_train_tfidf)\n",
    "X_test_lsa = lsa.transform(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2b0cd0",
   "metadata": {},
   "source": [
    "## 4. 머신러닝 모델들 성능 비교하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6c71ab",
   "metadata": {},
   "source": [
    "### 4.1 MultinomialNB 모델\n",
    "- MultinomialNB(다항 분포 나이브 베이즈)는 양수의 정수형 카운트 데이터(예: 단어 등장 횟수)를 기대하지만,\n",
    "- LSA(TruncatedSVD)를 적용하면 음수가 포함된 실수값이 나오기 때문에 MultinomialNB가 이를 처리할 수 없음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6daa1e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MultinomialNB()\n",
    "# model.fit(X_train_lsa, y_train)\n",
    "\n",
    "# predicted = model.predict(X_test_lsa) #테스트 데이터에 대한 예측\n",
    "# print(\"정확도:\", accuracy_score(y_test, predicted))\n",
    "# print(\"F1-score:\", f1_score(y_test, predicted, average='weighted'))\n",
    "# print(classification_report(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a1efe2",
   "metadata": {},
   "source": [
    "### 4.2 ComplementNB 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "805480fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cb = ComplementNB()\n",
    "# cb.fit(X_train_lsa, y_train)\n",
    "\n",
    "# predicted = cb.predict(X_test_lsa) #테스트 데이터에 대한 예측\n",
    "# print(\"정확도:\", accuracy_score(y_test, predicted))\n",
    "# print(\"F1-score:\", f1_score(y_test, predicted, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85395db8",
   "metadata": {},
   "source": [
    "### 4.3 Logistic Regression 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75fddf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.8054318788958148\n",
      "F1-score: 0.7989859476360002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C=10000, penalty='l2')\n",
    "lr.fit(X_train_lsa, y_train)\n",
    "\n",
    "predicted = lr.predict(X_test_lsa) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted))\n",
    "print(\"F1-score:\", f1_score(y_test, predicted, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9be60ce",
   "metadata": {},
   "source": [
    "### 4.4 선형 서포트 벡터 머신"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "370c1f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7920747996438112\n",
      "F1-score: 0.7854158503425255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lsvc = LinearSVC(C=1000, penalty='l1', max_iter=500, dual=False)\n",
    "lsvc.fit(X_train_lsa, y_train)\n",
    "\n",
    "predicted = lsvc.predict(X_test_lsa) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted))\n",
    "print(\"F1-score:\", f1_score(y_test, predicted, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669a502f",
   "metadata": {},
   "source": [
    "### 4.5 의사결정나무"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca344fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6825467497773821\n",
      "F1-score: 0.6518254536498507\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "tree.fit(X_train_lsa, y_train)\n",
    "\n",
    "predicted = tree.predict(X_test_lsa) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted))\n",
    "print(\"F1-score:\", f1_score(y_test, predicted, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd2c683",
   "metadata": {},
   "source": [
    "### 4.6 랜덤포레스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6874bf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7235084594835263\n",
      "F1-score: 0.7042786648375011\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=5, random_state=42)\n",
    "forest.fit(X_train_lsa, y_train)\n",
    "\n",
    "predicted = forest.predict(X_test_lsa) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted))\n",
    "print(\"F1-score:\", f1_score(y_test, predicted, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad95a52b",
   "metadata": {},
   "source": [
    "### 4.7 그래디언트 부스팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "484207e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7257346393588602\n",
      "F1-score: 0.7145644257630139\n"
     ]
    }
   ],
   "source": [
    "grbt = GradientBoostingClassifier(random_state=42, verbose=0) # \n",
    "grbt.fit(X_train_lsa, y_train)\n",
    "\n",
    "predicted = grbt.predict(X_test_lsa) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted))\n",
    "print(\"F1-score:\", f1_score(y_test, predicted, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3d1dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR\t20,000\t100\t0.8054\t0.7989\n",
    "LSVC\t\t\t0.7920\t0.7854\n",
    "DT\t\t\t0.6825\t0.6518\n",
    "RF\t\t\t0.7235\t0.7043\n",
    "GBT\t\t\t0.7257\t0.7145"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
